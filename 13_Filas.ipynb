{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/diogoflim/Pesquisa-Operacional-III-A/blob/main/13_Filas.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pesquisa Operacional III-A**\n",
    "\n",
    "**Professor:**\n",
    "- Diogo Ferreira de Lima Silva (TEP-UFF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício\n",
    "\n",
    "Suponha que temos uma fila onde os **tempos entre chegadas de clientes** seguem uma distribuição exponencial com média de 5 minutos. Simule a chegada de 20 clientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_clientes = 20\n",
    "tempos_entre_chegadas = np.random.exponential(scale=5.0, size=n_clientes)\n",
    "instantes_de_chegada = np.cumsum(tempos_entre_chegadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempos_entre_chegadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instantes_de_chegada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.step(range(1, n_clientes + 1), instantes_de_chegada, where='mid')\n",
    "plt.xlabel(\"Cliente\")\n",
    "plt.ylabel(\"Tempo de Chegada (min)\")\n",
    "plt.title(\"Simulação das Chegadas de Clientes\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2 \n",
    "\n",
    "Você é responsável por simular uma fila de atendimento.\n",
    "\n",
    "**Parâmetros:**\n",
    "- Os tempos entre chegadas seguem uma distribuição exponencial com média 3 minutos;\n",
    "- Os tempos de atendimento seguem uma distribuição uniforme entre 2 e 6 minutos.\n",
    "\n",
    "**Tarefa:**\n",
    "1. Simule a chegada de 30 clientes;\n",
    "2. Calcule os tempos de início e término do atendimento de cada cliente (considere um único atendente);\n",
    "3. Plote os gráficos:\n",
    "    - Tempo de espera de cada cliente;\n",
    "    - Tempo de sistema (espera + atendimento);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros\n",
    "n_clientes = 30\n",
    "media_chegada = 3.0\n",
    "tempo_min_atendimento = 2.0\n",
    "tempo_max_atendimento = 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração dos dados\n",
    "tempos_entre_chegadas = np.random.exponential(scale= media_chegada, size=n_clientes)\n",
    "instantes_chegada = np.cumsum(tempos_entre_chegadas)\n",
    "tempos_atendimento = np.random.uniform(low=tempo_min_atendimento, high=tempo_max_atendimento, size=n_clientes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (tempos_entre_chegadas[:10])\n",
    "\n",
    "print (instantes_chegada[:10])\n",
    "\n",
    "print(tempos_atendimento[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise da fila com um único atendente\n",
    "\n",
    "inicio_atendimento = np.zeros(n_clientes)\n",
    "fim_atendimento = np.zeros(n_clientes)\n",
    "tempo_espera = np.zeros(n_clientes)\n",
    "tempo_sistema = np.zeros(n_clientes)\n",
    "\n",
    "for i in range(n_clientes):\n",
    "    if i == 0:\n",
    "        inicio_atendimento[i] = instantes_chegada[i]\n",
    "    else:\n",
    "        inicio_atendimento[i] = max(instantes_chegada[i], fim_atendimento[i - 1])\n",
    "    fim_atendimento[i] = inicio_atendimento[i] + tempos_atendimento[i]\n",
    "    tempo_espera[i] = inicio_atendimento[i] - instantes_chegada[i]\n",
    "    tempo_sistema[i] = fim_atendimento[i] - instantes_chegada[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a tabela com pandas\n",
    "tabela = pd.DataFrame({\n",
    "    \"Cliente\": np.arange(1, n_clientes + 1),\n",
    "    \"Chegada (min)\": instantes_chegada,\n",
    "    \"Início Atendimento (min)\": inicio_atendimento,\n",
    "    \"Fim Atendimento (min)\": fim_atendimento,\n",
    "    \"Tempo de Espera (min)\": tempo_espera,\n",
    "    \"Tempo de Atendimento (min)\": tempos_atendimento,\n",
    "    \"Tempo no Sistema (min)\": tempo_sistema\n",
    "})\n",
    "\n",
    "# Exibir as primeiras linhas da tabela\n",
    "tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tempo de Espera por cliente\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(range(1, n_clientes + 1), tempo_espera, color='orange', edgecolor='black')\n",
    "plt.title(\"Tempo de Espera por Cliente\")\n",
    "plt.xlabel(\"Cliente\")\n",
    "plt.ylabel(\"Tempo de Espera (min)\")\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tempo Total no Sistema por Cliente\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(range(1, n_clientes + 1), tempo_sistema, color='green', edgecolor='black')\n",
    "plt.title(\"Tempo Total no Sistema por Cliente\")\n",
    "plt.xlabel(\"Cliente\")\n",
    "plt.ylabel(\"Tempo de Sistema (min)\")\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando a biblioteca simpy\n",
    "\n",
    "Para sistemas e experimentos mais complexos, será necessário utilizar uma biblioteca focada em Simulação. \n",
    "\n",
    "Vejamos o uso da biblioteca simpy para análise de alguns sistemas de filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install simpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpy # usado para a modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f2e3f1f-104a-4866-8644-b57898b944e9",
   "metadata": {},
   "source": [
    "### Exemplo de processo que não alcança estado estável\n",
    "\n",
    "Exemplo de processo M/M/2, com $\\lambda = 1$ cliente/minuto e $\\mu = 0,2$ clientes/minuto.\n",
    "\n",
    "Como $\\rho = \\frac{\\lambda}{s\\times \\mu} = \\frac{1}{0,4} >1$, é esperado que o processo não estabilize.\n",
    "\n",
    "A fila explodirá. \n",
    "\n",
    "Altere o código e calcule o tempo médio de espera dos clientes que finalizaram o serviço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20fac89-94eb-4f1f-83b1-f70d30d18640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estabelecimento (environment, nome_cliente, servidor):\n",
    "    #imprima na tela o tempo de chegada.\n",
    "    print (f\"{nome_cliente} chega ao estabelecimento em {environment.now}\") \n",
    "    \n",
    "    #guarde a informação na variável tempo_chegada.\n",
    "    tempo_chegada = environment.now \n",
    "    \n",
    "    # A atividade requer um servidor. Usamos o with para demonstrar isso. \n",
    "    with servidor.request() as req:\n",
    "        # Espere até o servidor estar disponível e guarde o tempo.\n",
    "        yield req \n",
    "        \n",
    "        # Escreva na tela o tempo de início do serviço\n",
    "        print (f\"{nome_cliente} inicia o serviço em {environment.now}\") \n",
    "        # guarde o tempo de início em uma variável chamada tempo_inicio\n",
    "        tempo_inicio = environment.now\n",
    "\n",
    "        # tempo de espera será o tempo_inicio - tempo_chegada \n",
    "        tempo_em_fila.append(tempo_inicio - tempo_chegada)\n",
    "\n",
    "        # O tempo estimado segue uma exponencial trabalha com Mu=0,2\n",
    "        yield environment.timeout(np.random.exponential(scale = 1/0.2))  \n",
    "        \n",
    "        #Imprima na tela o tempo de saída do sistema\n",
    "        print (f\"{nome_cliente} finaliza o serviço e sai do estabelecimento em {environment.now}\")\n",
    "        tempo_saida = environment.now\n",
    "        \n",
    "        # O tempo no sistema será tempo_saida - tempo_chegada\n",
    "        tempo_no_sistema.append(tempo_saida - tempo_chegada) \n",
    "\n",
    "def chegadas (environment):\n",
    "    id = 1 #guarda o id do cliente \n",
    "    \n",
    "    # Enquanto houver simulação:\n",
    "    while True:\n",
    "        # Passa um tempo até a próxima chegada, seguindo exponencial com média (1/lambda)\n",
    "        yield environment.timeout(np.random.exponential(1))\n",
    "        \n",
    "        # Um cliente chega no processo\n",
    "        environment.process(estabelecimento (environment, 'Cliente %d' % id, servidor))\n",
    "        \n",
    "        # O próximo cliente terá id = id + 1\n",
    "        id += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_em_fila = [] # uma lista vazia que receberá os tempos em fila\n",
    "tempo_no_sistema = [] # uma lista vazia que receberá os tempos no sistema de filas\n",
    "\n",
    "ambiente = simpy.Environment()\n",
    "servidor = simpy.Resource(ambiente, capacity=2)\n",
    "ambiente.process(chegadas(ambiente))\n",
    "ambiente.run(until = 480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Número de clientes que iniciaram o atendimento : {len(tempo_em_fila)}\")\n",
    "print (f\"O tempo de espera médio: {np.mean(tempo_em_fila).round(2)} minutos\")\n",
    "print (f\"O tempo médio no sistema: {np.mean(tempo_no_sistema).round(2)} minutos\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que o tempo de espera médio foi de mais de 2 horas.\n",
    "\n",
    "Na verdade, só contabilizamos tempos de espera que conseguiram iniciar o atendimento.\n",
    "\n",
    "Perceba que chegaram mais de 400 clientes e menos da metade deles foram atendidos.\n",
    "\n",
    "Seria interessante termos uma forma de guardar a utilização dos recursos e o número de clientes em fila!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisando Recursos\n",
    "\n",
    "A análise de recursos não é tão simples quanto guardar os tempos dos eventos. Para realizar uma análise efetiva, precisamos acessar os recursos após cada mudança no sistema.\n",
    "\n",
    "A boa notícia é que já há uma função pronta disponibilizada na documentação do SimPy, copiada na célula abaixo.\n",
    "\n",
    "Nesse código, usaremos decoradores de função (wrappers) para modificar recursos do SimPy, de modo que armazenaremos algumas características  antes e após alguma no mesmo.\n",
    "\n",
    "O código abaixo é semelhante ao disponível na documentação. Algumas modificações foram realizadas em termos usados e nos comentários.\n",
    "\n",
    "- https://simpy.readthedocs.io/en/latest/topical_guides/monitoring.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial, wraps\n",
    "\n",
    "def modifica_recurso (recurso, pre=None, post=None):\n",
    "    '''\n",
    "    Modificaremos o recurso para que este chame o *pre* antes de cada operação \n",
    "    e o *post* após cada operação.\n",
    "    *pre* e *post* fazem parte do wraps, que chamamos do pacote functools.\n",
    "    Operações típicas de recursos do SimPy são: put, get, request e release.\n",
    "    '''\n",
    "\n",
    "    def get_decorador(func):\n",
    "        \n",
    "        # Cria um decorador para as funções internas dos recursos: put/get/request/release\n",
    "        @wraps(func)\n",
    "        def decorador(*args, **kwargs):\n",
    "            # Chame o \"pre\" antes de aplicar a função\n",
    "            if pre:\n",
    "                pre(recurso)\n",
    "\n",
    "            # aplique a função\n",
    "            ret = func(*args, **kwargs)\n",
    "            \n",
    "            # Chame o \"post\" após aplicar a função\n",
    "            if post:\n",
    "                post(recurso)\n",
    "            \n",
    "            return ret #retorna o que a função retornaria\n",
    "        return decorador # retorna a função modificada pelo decorador\n",
    "\n",
    "    # Modifique a operação original pela modificada com o wrapper\n",
    "    for nome in ['put', 'get', 'request', 'release']:\n",
    "        \n",
    "        # Se acontecer uma operação do tipo nome no recurso em questão, mude os atributos\n",
    "        if hasattr(recurso, nome):\n",
    "            setattr(recurso, nome, get_decorador(getattr(recurso, nome)))\n",
    "\n",
    "\n",
    "# Armazenaremos o que queremos do recurso em questão em uma lista chamada dados\n",
    "def monitoramento(dados_controle, recurso):\n",
    "    item = (\n",
    "            recurso._env.now,  # O tempo de simulação na ocorrência de uma operação\n",
    "            recurso.count,  # Número de recursos do tipo em questão sendo utilizados\n",
    "            len(recurso.queue),  # Número de trabalhos em fila para o recurso\n",
    "    )   \n",
    "    dados_controle.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_em_fila = [] # uma lista vazia que receberá os tempos em fila\n",
    "tempo_no_sistema = [] # uma lista vazia que receberá os tempos no sistema de filas\n",
    "\n",
    "ambiente2 = simpy.Environment()\n",
    "servidor = simpy.Resource(ambiente2, capacity=2)\n",
    "\n",
    "dados_controle=[]\n",
    "monitoramento = partial(monitoramento, dados_controle)\n",
    "modifica_recurso (servidor, post = monitoramento)\n",
    "\n",
    "\n",
    "ambiente2.process(chegadas(ambiente2))\n",
    "ambiente2.run(until = 480)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vejamos os dados que conseguimos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_controle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizando os dados dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servidor_dados = pd.DataFrame(dados_controle, columns = [\"Tempo\", \"Servidores Trabalhando\", \"Lq\"])\n",
    "servidor_dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podemos adicionar uma linha no topo para ser o estado inicial, quando nenhum cliente chegou:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servidor_dados.loc[-1] = [0.0, 0, 0]  # adding a row\n",
    "servidor_dados.index = servidor_dados.index + 1  # shifting index\n",
    "servidor_dados.sort_index(inplace=True) \n",
    "servidor_dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agora adicionarems uma linha no fim com o estado do sistema no momento 480."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servidor_dados.loc[len(servidor_dados)] = [480, 2, 333]\n",
    "servidor_dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queremos o tempo em que observamos cada estado antes de um novo evento!\n",
    "\n",
    "Podemos chegar a isso com \"servidor_1.diff()\" aplicado à coluna tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servidor_dados[\"Intervalo\"] = servidor_dados[\"Tempo\"].diff().shift(-1)\n",
    "servidor_dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A última linha ficou com um NaN. Vamos excluí-la:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servidor_dados = servidor_dados.dropna(axis = 0)\n",
    "servidor_dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculando métricas interessantes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Número médio de clientes em fila\n",
    "\n",
    "\n",
    "Sabemos que a fila está explodindo. Vejamos a média de clientes em fila nesses 480 min simulados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servidor_dados[\"Intervalo\"] @ servidor_dados[\"Lq\"] / servidor_dados[\"Intervalo\"].sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso dos servidores, lembrando que em nosso exemplo $s=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servidor_dados[\"Intervalo\"] @ servidor_dados[\"Servidores Trabalhando\"] / servidor_dados[\"Intervalo\"].sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porcentagem do tempo que não temos ninguem no sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servidor_ocioso = servidor_dados[servidor_dados[\"Servidores Trabalhando\"] == 0]\n",
    "servidor_ocioso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servidor_ocioso[\"Intervalo\"].sum() / servidor_dados[\"Intervalo\"].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "po3a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
